[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Homework 5",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Homework 5",
    "section": "",
    "text": "Dataframe\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nNFL2022_stuffs &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_stuffs.csv')\n\nVariable description\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play game_id: Ten digit identifier for NFL game. drive: Numeric drive number in the game. week: Season week. posteam: String abbreviation for the team with possession. qtr: Quarter of the game (5 is overtime). half_seconds_remaining: Numeric seconds remaining in the half. down: The down for the given play. Basically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it). If you make 10 yards then you get another set of four downs. pass: Binary indicator if the play was a pass play. wp: Estimated winning probability for the posteam given the current situation at the start of the given play.\nQ2b.\nSummarize the mean value of pass for each posteam when all the following conditions hold: wp is greater than 20% and less than 75%; down is less than or equal to 2; and half_seconds_remaining is greater than 120.\n\nfiltered_data &lt;- NFL2022_stuffs %&gt;%\n  filter(wp &gt; 0.2 & wp &lt; 0.75 & down &lt;= 2 & half_seconds_remaining &gt; 120)\n\nsummary_data &lt;- filtered_data %&gt;%\n  group_by(posteam) %&gt;%\n  summarize(mean_pass = mean(pass, na.rm = TRUE))\n\nprint(summary_data)\n\n# A tibble: 32 × 2\n   posteam mean_pass\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 ARI         0.553\n 2 ATL         0.4  \n 3 BAL         0.520\n 4 BUF         0.604\n 5 CAR         0.458\n 6 CHI         0.420\n 7 CIN         0.657\n 8 CLE         0.491\n 9 DAL         0.474\n10 DEN         0.493\n# ℹ 22 more rows\n\n\nQ2c.\nProvide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam. In the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\n\nlibrary(ggplot2)\n\nsummary_data &lt;- summary_data[order(summary_data$mean_pass), ]\n\n\nggplot(summary_data, aes(x = reorder(posteam, mean_pass), y = mean_pass)) +\n  geom_point() +\n  labs(title = \"Mean Value of Pass for Each posteam\",\n       x = \"posteam\",\n       y = \"Mean Pass Value\") +\n  theme_minimal()\n\n\n\n\nQ2d. Consider the following data.frame, NFL2022_epa:\n\nNFL2022_epa &lt;- read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\nRows: 46427 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): game_id, posteam, receiver, passer\ndbl (3): play_id, drive, epa\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nVariable description for NFL2022_epa\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play game_id: Ten digit identifier for NFL game. drive: Numeric drive number in the game. posteam: String abbreviation for the team with possession. passer: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks) receiver: Name of the receiver. epa: Expected points added (EPA) by the posteam for the given play. Create the data.frame, NFL2022_stuffs_EPA, that includes\nAll the variables in the data.frame, NFL2022_stuffs; The variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames. In the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\n\nlibrary(dplyr)\nNFL2022_stuffs_EPA &lt;- left_join(NFL2022_stuffs, NFL2022_epa %&gt;% select(play_id, passer, receiver, epa), by = \"play_id\")\n\nWarning in left_join(NFL2022_stuffs, NFL2022_epa %&gt;% select(play_id, passer, : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 2 of `x` matches multiple rows in `y`.\nℹ Row 24 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nNFL2022_stuffs_EPA &lt;- NFL2022_stuffs_EPA %&gt;% filter(!is.na(passer))\nhead(NFL2022_stuffs_EPA)\n\n  play_id         game_id drive week posteam qtr down half_seconds_remaining\n1      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n2      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n3      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n4      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n5      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n6      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n  pass        wp     passer        receiver         epa\n1    0 0.5469690  L.Jackson       M.Andrews  1.63733703\n2    0 0.5469690 J.Brissett D.Peoples-Jones  2.62984087\n3    0 0.5469690 D.Prescott       E.Elliott  0.86737985\n4    1 0.5725734   J.Flacco       Mi.Carter -0.49219242\n5    1 0.5725734  L.Jackson       J.Dobbins -0.01652313\n6    1 0.5725734 T.Lawrence          C.Kirk -0.84493633\n\n\nQ2e.\nProvide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers, “J.Allen” “P.Mahomes”\n\nlibrary(ggplot2)\nfiltered_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(passer %in% c(\"J.Allen\", \"P.Mahomes\"))\nggplot(filtered_data, aes(x = week, y = epa, group = passer, color = passer)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Weekly Trend of Mean EPA for J.Allen and P.Mahomes\",\n       x = \"Week\",\n       y = \"Mean EPA\") +\n  theme_minimal()\n\n\n\n\nCalculate the difference between the mean value of epa for “J.Allen” the mean value of epa for “P.Mahomes” for each value of week.\n\nmean_epa_by_week &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(week, passer) %&gt;%\n  summarize(mean_epa = mean(epa, na.rm = TRUE), .groups = 'drop')\nmean_epa_wide &lt;- mean_epa_by_week %&gt;%\n  pivot_wider(names_from = passer, values_from = mean_epa)\nmean_epa_wide$epa_difference &lt;- mean_epa_wide$J.Allen - mean_epa_wide$P.Mahomes\nhead(mean_epa_wide)\n\n# A tibble: 6 × 116\n   week A.Brown A.Cooper A.Dalton A.Rodgers B.Allen B.Berrios B.Gabbert  B.Hoyer\n  &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1     1  -0.203    -4.98   0.0899    0.0223  -0.726      1.18   -0.278   0.143  \n2     2  -0.287    -4.98   0.181     0.115   -0.419      1.18    0.0682  0.311  \n3     3  -0.442    -4.98   0.146     0.0556  NA         NA       0.0553 -0.364  \n4     4  -0.964    -4.98   0.0977    0.0261  -0.457      1.18   -0.681   0.00372\n5     5   0.150    -4.98   0.0304    0.0523  -1.07      NA      -1.08    0.633  \n6     6  -0.192    -4.98   0.0561   -0.0104  -1.14       1.18   -0.438  -0.201  \n# ℹ 107 more variables: B.Mann &lt;dbl&gt;, B.Mayfield &lt;dbl&gt;, B.Perkins &lt;dbl&gt;,\n#   B.Purdy &lt;dbl&gt;, B.Rypien &lt;dbl&gt;, B.Zappe &lt;dbl&gt;, C.Beathard &lt;dbl&gt;,\n#   C.Daniel &lt;dbl&gt;, C.Henne &lt;dbl&gt;, C.Keenum &lt;dbl&gt;, C.McCaffrey &lt;dbl&gt;,\n#   C.McCoy &lt;dbl&gt;, C.Rush &lt;dbl&gt;, C.Streveler &lt;dbl&gt;, C.Wentz &lt;dbl&gt;,\n#   C.Wilson &lt;dbl&gt;, D.Adams &lt;dbl&gt;, D.Blough &lt;dbl&gt;, D.Carr &lt;dbl&gt;, D.Cook &lt;dbl&gt;,\n#   D.Dallas &lt;dbl&gt;, D.Jones &lt;dbl&gt;, D.Mills &lt;dbl&gt;, D.Prescott &lt;dbl&gt;,\n#   D.Ridder &lt;dbl&gt;, D.Watson &lt;dbl&gt;, D.Webb &lt;dbl&gt;, `G.Minshew II` &lt;dbl&gt;, …\n\n\nSummarize the resulting data.frame in Q2d, with the following four variables:\nposteam: String abbreviation for the team with possession. passer: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.) mean_epa: Mean value of epa in 2022 for each passer n_pass: Number of observations for each passer Then find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\n\npasser_summary &lt;- NFL2022_stuffs_EPA %&gt;%\n  select(week, passer, epa) %&gt;%\n  group_by(week, passer, .drop = TRUE) %&gt;%\n  summarize(mean_epa = mean(epa, na.rm = TRUE),\n            n_pass = sum(!is.na(epa)), .groups = 'drop')\nquantile_threshold &lt;- quantile(passer_summary$n_pass, 0.75)\ntop_passers &lt;- passer_summary %&gt;%\n  filter(n_pass &gt;= quantile_threshold) %&gt;%\n  arrange(desc(mean_epa)) %&gt;%\n  head(10)\ntop_passers\n\n# A tibble: 10 × 4\n    week passer       mean_epa n_pass\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;  &lt;int&gt;\n 1    11 P.Mahomes       0.426    601\n 2     7 P.Mahomes       0.410    543\n 3     9 T.Tagovailoa    0.398    266\n 4     6 T.Tagovailoa    0.396    259\n 5     8 J.Garoppolo     0.375    238\n 6    15 P.Mahomes       0.369    631\n 7     8 P.Mahomes       0.368    544\n 8    18 P.Mahomes       0.364    612\n 9     4 J.Garoppolo     0.355    268\n10    16 P.Mahomes       0.344    652"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe’ll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI’ll begin with these analyses and create visualizations to help us understand the data better. Let’s start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let’s calculate the average quantity purchased and average spending per purchase. For this, we’ll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we’ll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we’ll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let’s move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI’ll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let’s look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let’s proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe’ll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we’ll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let’s calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there’s a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let’s move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe’ll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We’ll do this for each brand to see which brands are most affected by promotions.\nLet’s begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn’t. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lucas Rosa",
    "section": "",
    "text": "Lucas Rosa is majoring in accounting at SUNY Geneseo. When not working on accounting, Lucas enjoys spending time playing basketball and going to the gym"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Lucas Rosa",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Accounting | Aug 2022 - May 2026"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Lucas Rosa",
    "section": "Experience",
    "text": "Experience\nLumberyard Worker | Weis cashier | May 2024 - Aug 2024"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nHomework 5\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nLucas Rosa\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "",
    "text": "olympic &lt;- read_csv('/Users/lucasrosa/Downloads/olympic_games.csv')\nnvars &lt;- format(round(ncol(olympic), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(olympic), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 11; the number of observations is 1,781."
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL Project",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\nmpg &lt;- ggplot2::mpg\n\n\n\n\n  \n\n\n\nskim(mpg) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n1\n4\n10\n0\n15\n0\n\n\nmodel\n1\n2\n22\n0\n38\n0\n\n\ntrans\n1\n8\n10\n0\n10\n0\n\n\ndrv\n1\n1\n1\n0\n3\n0\n\n\nfl\n1\n1\n1\n0\n5\n0\n\n\nclass\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n▇▆▆▃▁\n\n\nyear\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n▇▁▁▁▇\n\n\ncyl\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n▇▁▇▁▇\n\n\ncty\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n▆▇▃▁▁\n\n\nhwy\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n▅▅▇▁▁"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "DANL Project",
    "section": "2.2 MPG and a Type of Cars",
    "text": "2.2 MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) 🚙 🚚 🚐.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "project.html#data-visualization",
    "href": "project.html#data-visualization",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.1 Data Visualization",
    "text": "2.1 Data Visualization\n\ntop10 &lt;- olympic %&gt;% \n  arrange(desc(gold)) %&gt;%\n  head(10)\n\nprint(top10)\n\n# A tibble: 10 × 11\n    year games_type host_country   host_city athletes teams competitions country\n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;  \n 1  1984 Summer     United States  Los Ange…     6829   140          221 United…\n 2  1980 Summer     USSR           Moscow        5179    80          203 USSR   \n 3  1904 Summer     United States  St. Louis      651    12           95 United…\n 4  1908 Summer     Great Britain  London        2008    22          110 United…\n 5  1988 Summer     Republic of K… Seoul         8397   159          237 USSR   \n 6  1972 Summer     Federal Repub… Munich        7134   121          195 USSR   \n 7  1976 Summer     Canada         Montreal      6084    92          198 USSR   \n 8  2012 Summer     Great Britain  London       10568   204          302 United…\n 9  2008 Summer     China          Beijing      10942   204          302 People…\n10  1980 Summer     USSR           Moscow        5179    80          203 German…\n# ℹ 3 more variables: gold &lt;dbl&gt;, silver &lt;dbl&gt;, bronze &lt;dbl&gt;"
  },
  {
    "objectID": "project.html#analysis",
    "href": "project.html#analysis",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.2 Analysis",
    "text": "2.2 Analysis\nFrom my data we can see that the USSR has won the most amount of metals out of the top 10 countries that won the largest number of gold metals over 10 separate years. From this I can conclude that the USSR is most likely to win the most gold metals in future years. ## Quotes\n\n“Gold medal always feels great. In fact, any appreciation or acknowledgement is a great morale booster”\nDutee Chand"
  },
  {
    "objectID": "project.html#inserting-figures",
    "href": "project.html#inserting-figures",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.3 Inserting Figures",
    "text": "2.3 Inserting Figures\n\nggplot(top10, aes(x = reorder(country, gold), y = gold)) +\n  geom_bar(stat = \"identity\", fill = \"gold\") +\n  labs(title = \"Countries with the Most Gold Medals in Olympics\",\n       x = \"Country\",\n       y = \"Total Gold Medals\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "project.html#inserting-a-html-page",
    "href": "project.html#inserting-a-html-page",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.4 Inserting a HTML page",
    "text": "2.4 Inserting a HTML page"
  },
  {
    "objectID": "posts/post-with-code copy/index.html",
    "href": "posts/post-with-code copy/index.html",
    "title": "Homework 5",
    "section": "",
    "text": "Dataframe\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nNFL2022_stuffs &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_stuffs.csv')\n\nVariable description\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play game_id: Ten digit identifier for NFL game. drive: Numeric drive number in the game. week: Season week. posteam: String abbreviation for the team with possession. qtr: Quarter of the game (5 is overtime). half_seconds_remaining: Numeric seconds remaining in the half. down: The down for the given play. Basically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it). If you make 10 yards then you get another set of four downs. pass: Binary indicator if the play was a pass play. wp: Estimated winning probability for the posteam given the current situation at the start of the given play.\nQ2b.\nSummarize the mean value of pass for each posteam when all the following conditions hold: wp is greater than 20% and less than 75%; down is less than or equal to 2; and half_seconds_remaining is greater than 120.\n\nfiltered_data &lt;- NFL2022_stuffs %&gt;%\n  filter(wp &gt; 0.2 & wp &lt; 0.75 & down &lt;= 2 & half_seconds_remaining &gt; 120)\n\nsummary_data &lt;- filtered_data %&gt;%\n  group_by(posteam) %&gt;%\n  summarize(mean_pass = mean(pass, na.rm = TRUE))\n\nprint(summary_data)\n\n# A tibble: 32 × 2\n   posteam mean_pass\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 ARI         0.553\n 2 ATL         0.4  \n 3 BAL         0.520\n 4 BUF         0.604\n 5 CAR         0.458\n 6 CHI         0.420\n 7 CIN         0.657\n 8 CLE         0.491\n 9 DAL         0.474\n10 DEN         0.493\n# ℹ 22 more rows\n\n\nQ2c.\nProvide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam. In the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\n\nlibrary(ggplot2)\n\nsummary_data &lt;- summary_data[order(summary_data$mean_pass), ]\n\n\nggplot(summary_data, aes(x = reorder(posteam, mean_pass), y = mean_pass)) +\n  geom_point() +\n  labs(title = \"Mean Value of Pass for Each posteam\",\n       x = \"posteam\",\n       y = \"Mean Pass Value\") +\n  theme_minimal()\n\n\n\n\nQ2d. Consider the following data.frame, NFL2022_epa:\n\nNFL2022_epa &lt;- read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\nRows: 46427 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): game_id, posteam, receiver, passer\ndbl (3): play_id, drive, epa\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nVariable description for NFL2022_epa\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play game_id: Ten digit identifier for NFL game. drive: Numeric drive number in the game. posteam: String abbreviation for the team with possession. passer: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks) receiver: Name of the receiver. epa: Expected points added (EPA) by the posteam for the given play. Create the data.frame, NFL2022_stuffs_EPA, that includes\nAll the variables in the data.frame, NFL2022_stuffs; The variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames. In the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\n\nlibrary(dplyr)\nNFL2022_stuffs_EPA &lt;- left_join(NFL2022_stuffs, NFL2022_epa %&gt;% select(play_id, passer, receiver, epa), by = \"play_id\")\n\nWarning in left_join(NFL2022_stuffs, NFL2022_epa %&gt;% select(play_id, passer, : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 2 of `x` matches multiple rows in `y`.\nℹ Row 24 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nNFL2022_stuffs_EPA &lt;- NFL2022_stuffs_EPA %&gt;% filter(!is.na(passer))\nhead(NFL2022_stuffs_EPA)\n\n  play_id         game_id drive week posteam qtr down half_seconds_remaining\n1      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n2      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n3      68 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1796\n4      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n5      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n6      89 2022_01_BAL_NYJ     1    1     NYJ   1    1                   1769\n  pass        wp     passer        receiver         epa\n1    0 0.5469690  L.Jackson       M.Andrews  1.63733703\n2    0 0.5469690 J.Brissett D.Peoples-Jones  2.62984087\n3    0 0.5469690 D.Prescott       E.Elliott  0.86737985\n4    1 0.5725734   J.Flacco       Mi.Carter -0.49219242\n5    1 0.5725734  L.Jackson       J.Dobbins -0.01652313\n6    1 0.5725734 T.Lawrence          C.Kirk -0.84493633\n\n\nQ2e.\nProvide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers, “J.Allen” “P.Mahomes”\n\nlibrary(ggplot2)\nfiltered_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(passer %in% c(\"J.Allen\", \"P.Mahomes\"))\nggplot(filtered_data, aes(x = week, y = epa, group = passer, color = passer)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Weekly Trend of Mean EPA for J.Allen and P.Mahomes\",\n       x = \"Week\",\n       y = \"Mean EPA\") +\n  theme_minimal()\n\n\n\n\nCalculate the difference between the mean value of epa for “J.Allen” the mean value of epa for “P.Mahomes” for each value of week.\n\nmean_epa_by_week &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(week, passer) %&gt;%\n  summarize(mean_epa = mean(epa, na.rm = TRUE), .groups = 'drop')\nmean_epa_wide &lt;- mean_epa_by_week %&gt;%\n  pivot_wider(names_from = passer, values_from = mean_epa)\nmean_epa_wide$epa_difference &lt;- mean_epa_wide$J.Allen - mean_epa_wide$P.Mahomes\nhead(mean_epa_wide)\n\n# A tibble: 6 × 116\n   week A.Brown A.Cooper A.Dalton A.Rodgers B.Allen B.Berrios B.Gabbert  B.Hoyer\n  &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1     1  -0.203    -4.98   0.0899    0.0223  -0.726      1.18   -0.278   0.143  \n2     2  -0.287    -4.98   0.181     0.115   -0.419      1.18    0.0682  0.311  \n3     3  -0.442    -4.98   0.146     0.0556  NA         NA       0.0553 -0.364  \n4     4  -0.964    -4.98   0.0977    0.0261  -0.457      1.18   -0.681   0.00372\n5     5   0.150    -4.98   0.0304    0.0523  -1.07      NA      -1.08    0.633  \n6     6  -0.192    -4.98   0.0561   -0.0104  -1.14       1.18   -0.438  -0.201  \n# ℹ 107 more variables: B.Mann &lt;dbl&gt;, B.Mayfield &lt;dbl&gt;, B.Perkins &lt;dbl&gt;,\n#   B.Purdy &lt;dbl&gt;, B.Rypien &lt;dbl&gt;, B.Zappe &lt;dbl&gt;, C.Beathard &lt;dbl&gt;,\n#   C.Daniel &lt;dbl&gt;, C.Henne &lt;dbl&gt;, C.Keenum &lt;dbl&gt;, C.McCaffrey &lt;dbl&gt;,\n#   C.McCoy &lt;dbl&gt;, C.Rush &lt;dbl&gt;, C.Streveler &lt;dbl&gt;, C.Wentz &lt;dbl&gt;,\n#   C.Wilson &lt;dbl&gt;, D.Adams &lt;dbl&gt;, D.Blough &lt;dbl&gt;, D.Carr &lt;dbl&gt;, D.Cook &lt;dbl&gt;,\n#   D.Dallas &lt;dbl&gt;, D.Jones &lt;dbl&gt;, D.Mills &lt;dbl&gt;, D.Prescott &lt;dbl&gt;,\n#   D.Ridder &lt;dbl&gt;, D.Watson &lt;dbl&gt;, D.Webb &lt;dbl&gt;, `G.Minshew II` &lt;dbl&gt;, …\n\n\nSummarize the resulting data.frame in Q2d, with the following four variables:\nposteam: String abbreviation for the team with possession. passer: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.) mean_epa: Mean value of epa in 2022 for each passer n_pass: Number of observations for each passer Then find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\n\npasser_summary &lt;- NFL2022_stuffs_EPA %&gt;%\n  select(week, passer, epa) %&gt;%\n  group_by(week, passer, .drop = TRUE) %&gt;%\n  summarize(mean_epa = mean(epa, na.rm = TRUE),\n            n_pass = sum(!is.na(epa)), .groups = 'drop')\nquantile_threshold &lt;- quantile(passer_summary$n_pass, 0.75)\ntop_passers &lt;- passer_summary %&gt;%\n  filter(n_pass &gt;= quantile_threshold) %&gt;%\n  arrange(desc(mean_epa)) %&gt;%\n  head(10)\ntop_passers\n\n# A tibble: 10 × 4\n    week passer       mean_epa n_pass\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;  &lt;int&gt;\n 1    11 P.Mahomes       0.426    601\n 2     7 P.Mahomes       0.410    543\n 3     9 T.Tagovailoa    0.398    266\n 4     6 T.Tagovailoa    0.396    259\n 5     8 J.Garoppolo     0.375    238\n 6    15 P.Mahomes       0.369    631\n 7     8 P.Mahomes       0.368    544\n 8    18 P.Mahomes       0.364    612\n 9     4 J.Garoppolo     0.355    268\n10    16 P.Mahomes       0.344    652"
  }
]